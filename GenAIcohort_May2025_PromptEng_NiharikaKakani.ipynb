{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqI5YTAhFx+24baLVOfvGv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niharika-2002/GenAi_May2025/blob/main/GenAIcohort_May2025_PromptEng_NiharikaKakani.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxJE40P95ljx",
        "outputId": "75bc8c9f-9490-49bb-9ff1-c2dbc5da4c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api')\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key"
      ],
      "metadata": {
        "id": "e6IossiF59FT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of large language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-8b-8192\",\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3V2c2s76CwZ",
        "outputId": "e6dc7d89-4630-4f66-9632-d981ef9a1323"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large language models (LLMs) have revolutionized the field of natural language processing (NLP) and have far-reaching implications for various industries and applications. Here are some of the key importance of large language models:\n",
            "\n",
            "1. **Improved Conversational AI**: LLMs have enabled the development of more conversational and intuitive AI chatbots, virtual assistants, and voice assistants. These systems can understand and respond to complex requests, making them more useful in various applications, such as customer service, gaming, and virtual reality.\n",
            "2. **Text Classification**: LLMs have achieved state-of-the-art performance in text classification tasks, such as sentiment analysis, spam detection, and topic modeling. This has significant implications for industries that rely heavily on text-based data, such as customer service, marketing, and finance.\n",
            "3. **Language Translation**: LLMs have improved language translation capabilities, enabling more accurate and fluent translations. This has opened up new opportunities for global communication, commerce, and cultural exchange.\n",
            "4. **Question Answering**: LLMs have enabled the development of question-answering systems that can accurately extract information from large repositories of text data. This has implications for industries that rely on information retrieval, such as search engines, libraries, and research institutions.\n",
            "5. **Content Generation**: LLMs have the ability to generate human-like text, including articles, social media posts, and even entire books. This has significant implications for content creation, publishing, and marketing.\n",
            "6. **Improved Search Engines**: LLMs have enabled the development of more advanced search engines that can understand the nuances of natural language and provide more accurate and relevant search results.\n",
            "7. **Customer Service**: LLMs have already been deployerd in customer service applications, enabling companies to provide more personalized and efficient customer support.\n",
            "8. **Healthcare**: LLMs have the potential to improve healthcare applications, such as medical diagnosis, patient care, and clinical research.\n",
            "9. **Education**: LLMs have the potential to revolutionize education by enabling the development of more personalized and adaptive learning systems.\n",
            "10. **Scientific Discovery**: LLMs have the potential to accelerate scientific discovery by enabling the analysis of large datasets and the identification of patterns and relationships that may not be apparent to humans.\n",
            "11. **Improved Dialogue Systems**: LLMs have improved dialogue systems, enabling more human-like and natural conversations between humans and machines.\n",
            "12. **Enhanced Accessibility**: LLMs have the potential to improve accessibility for people with disabilities, such as speech impairments or reading difficulties.\n",
            "13. **Cybersecurity**: LLMs have the potential to improve cybersecurity by enabling more effective detection and prevention of cyber threats.\n",
            "14. **Automated Summarization**: LLMs have enabled the development of automated summarization systems that can quickly summarize large documents and provide important information.\n",
            "15. **Improved Customer Insights**: LLMs have the potential to provide more accurate and detailed customer insights, enabling companies to better understand their customers and improve their products and services.\n",
            "\n",
            "Overall, large language models have the potential to transform many aspects of our lives, from customer service and healthcare to education and scientific discovery.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 1: Summary Extraction"
      ],
      "metadata": {
        "id": "nNHZxsQT6WS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove special symbols and multiple punctuation\n",
        "    text = re.sub(r'[^\\w\\s\\.\\,\\-\\']', ' ', text)  # keep alphanumerics and punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)  # replace multiple spaces with one\n",
        "    text = re.sub(r'\\.\\.+', '.', text)  # replace ellipses with a single period\n",
        "    text = re.sub(r'(?<=\\w)[A-Z]', lambda x: ' ' + x.group(0), text)  # fix camel-case issues\n",
        "    text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)  # remove space before punctuation\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "HnTM_m8a6aTA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text):\n",
        "    cleaned = clean_text(text)\n",
        "    prompt = f\"Summarise my text: {cleaned}\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "G1tJBDlB66Fg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = \"\"\"\n",
        "Black..... holes—those mysterious cosmic phenomena—are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha### have dived deeply into the “science” of these objects, uncovering fascinating insights! According to Rothwell’s research (2021), black holes form when massive stars burn ^^^^through their fuel & collapse under gravity until they reach a singularity—a point of (nearly) infinite density, where physics bReak dOwn.\n",
        "\n",
        "Sinha’s studies focus on the event horizon, or the “point of no return”; any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation—a theoretical ....concept from Stephen Hawking—suggesting that black holes.... emit small amounts of energy...., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities!!!!. Together, Rothwell and Sinha’s studies hint at bridging quantum mechanics w/ general relativity—fields otherwise tough to reconcile!\n",
        "\"\"\"\n",
        "\n",
        "cleaned = clean_text(raw_text)\n",
        "prompt = summarize_text(raw_text)\n",
        "\n",
        "print(\"Cleaned Text:\\n\", cleaned)\n",
        "print(\"\\nPrompt:\\n\", prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhZ1CKgf7USV",
        "outputId": "d764bbce-e35f-4379-d980-144676099249"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            " Black. holes those mysterious cosmic phenomena are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha have dived deeply into the science of these objects, uncovering fascinating insights According to Rothwell s research 2021, black holes form when massive stars burn through their fuel collapse under gravity until they reach a singularity a point of nearly infinite density, where physics b Reak d Own. Sinha s studies focus on the event horizon, or the point of no return any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation a theoretical .concept from Stephen Hawking suggesting that black holes. emit small amounts of energy., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities. Together, Rothwell and Sinha s studies hint at bridging quantum mechanics w general relativity fields otherwise tough to reconcile\n",
            "\n",
            "Prompt:\n",
            " Summarise my text: Black. holes those mysterious cosmic phenomena are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha have dived deeply into the science of these objects, uncovering fascinating insights According to Rothwell s research 2021, black holes form when massive stars burn through their fuel collapse under gravity until they reach a singularity a point of nearly infinite density, where physics b Reak d Own. Sinha s studies focus on the event horizon, or the point of no return any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation a theoretical .concept from Stephen Hawking suggesting that black holes. emit small amounts of energy., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities. Together, Rothwell and Sinha s studies hint at bridging quantum mechanics w general relativity fields otherwise tough to reconcile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q litellm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFh1NYyr7yhv",
        "outputId": "bf151958-b561-4287-e0ab-f1ed48f731cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/8.0 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/8.0 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/8.0 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m5.7/8.0 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m7.4/8.0 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion"
      ],
      "metadata": {
        "id": "GL_2V4ll7ygt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt):\n",
        "  #define model\n",
        "  model=\"groq/llama3-70b-8192\"\n",
        "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "  #call responses\n",
        "  response = completion(\n",
        "      model=model,\n",
        "      messages=messages\n",
        "  )\n",
        "\n",
        "  return response['choices'][0]['message']['content'] or \"\"\n"
      ],
      "metadata": {
        "id": "oPo7rErJ7_df"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = get_response(prompt)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLNB0aQX8DZp",
        "outputId": "c405e732-c7f7-4a28-a623-ae3eae61d424"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a concise summary of your text:\n",
            "\n",
            "Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha, have made significant contributions to our understanding of black holes. Rothwell's research shows that black holes are created when massive stars collapse into a singularity, where physics breaks down. Sinha's work explores the event horizon, where anything that crosses it is trapped, and Hawking Radiation, which suggests that black holes slowly lose mass, potentially allowing scientists to glimpse inside. Their studies collectively aim to bridge the gap between quantum mechanics and general relativity, two fields that have been difficult to reconcile.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 2: Sentiment Analysis"
      ],
      "metadata": {
        "id": "z22R-tWn8Nc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(review):\n",
        "    prompt = f\"\"\"\n",
        "Your task is to classify the sentiment of a user's review as Positive, Negative, or Neutral.\n",
        "\n",
        ": I absolutely loved the new update—it’s so user-friendly and fast!\n",
        ": Positive\n",
        "\n",
        ": {review}\n",
        ":\"\"\"\n",
        "\n",
        "    return get_response(prompt).strip()\n"
      ],
      "metadata": {
        "id": "QCryTPoT8MUn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"The biometric was available for few days only.\"\n",
        "sentiment = get_sentiment(review)\n",
        "print(\"Sentiment:\", sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUo-eW3L8S2M",
        "outputId": "d35c29dc-7921-4946-ffdb-050b38447bb7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: : Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 3: Intelligent Resume Filtering using Keyword Extraction"
      ],
      "metadata": {
        "id": "mNY66El_81av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"You are a resume query assistant. Your task is to help a hiring manager filter potential candidates from a MongoDB collection named `resumes`. The manager gives you a natural language query, and your job is to extract relevant keywords and construct a valid PyMongo-style MongoDB query.\n",
        "\n",
        "You must:\n",
        "- Use only the following filters: [\"work_experience\", \"technical_skills\", \"designation\", \"education\", \"location\"]\n",
        "- Map the keywords from the query to the appropriate filter\n",
        "- Normalize common terms (e.g., map \"2 years experience\" to \"work_experience\": {\"eq\": 2}) - Represent \"skills\" as a list under \"technical_skills\" using `\n",
        "in`\n",
        "- Ignore candidate names or unrelated information\n",
        "- Only use filters that are present in the query (don't add empty ones)\n",
        "- Output only a single valid Python dictionary representing the MongoDB query\n",
        "- If information is ambiguous, make reasonable assumptions and comment them in the output\n",
        "\n",
        "Example input:\n",
        "\n",
        "Hiring Manager Query: \"Get me candidates with 2 years experience in python and flask and ready to work in Banglore\"\n",
        "\n",
        "Output:\n",
        "{\n",
        "  \"work_experience\": { \"$eq\": 2 },\n",
        "  \"technical_skills\": { \"$in\": [\"Python\", \"Flask\"] },\n",
        "  \"location\": \"Bangalore\"\n",
        "}\n",
        "\n",
        "Now process this query:\n",
        "\"Get me candidates with 5 years experience in python and AI and ready to work in Hyd\"\n",
        "\"\"\"\n",
        "response=get_response(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCB7lNJX9neF",
        "outputId": "f2480cc8-f813-4b98-8272-a9e2e7c4c707"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the output:\n",
            "\n",
            "{\n",
            "  \"work_experience\": { \"$eq\": 5 },\n",
            "  \"technical_skills\": { \"$in\": [\"Python\", \"AI\"] },\n",
            "  \"location\": \"Hyd\"  # Assuming Hyd is a common abbreviation for Hyderabad\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment: Building a Smart Assistant for Virtual Healthcare Support**"
      ],
      "metadata": {
        "id": "8nOl2Bfu_Bci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement: Given a doctor-patient conversation, the AI assistant should help by:\n",
        "\n",
        "Detecting the patient's emotional state. Give a score on a scale of 1-5.\n",
        "Summarizing the chief complaint and urgency of the patient."
      ],
      "metadata": {
        "id": "H7Nq_IPh_gvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q groq langchain-groq langchain langchain-community langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DBGcezx_EXZ",
        "outputId": "2be43875-091d-4ff7-951e-7263f00889e2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.tools import tool\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from typing import List\n",
        "from litellm import completion\n",
        "from langchain.agents import initialize_agent, Tool, AgentType"
      ],
      "metadata": {
        "id": "wcUwYdqK_vb0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\", #\"llama-3.1-8b-instant,llama-3.3-70b-versatile\",\n",
        "    temperature=0, # range of temperature variable is from 0(least artistic) to 1(most artistic/enhanced)\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "xlzs0meW_9tC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_core.language_models import BaseLanguageModel\n",
        "\n",
        "\n",
        "@tool\n",
        "def detect_patient_emotion(conversation: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyzes a doctor-patient conversation to extract:\n",
        "    1. Patient's emotion (e.g., anxious, calm, in pain)\n",
        "    2. Emotion score on a scale from 1 to 5 (1 = very distressed, 5 = calm)\n",
        "\n",
        "    Parameters:\n",
        "    - conversation (str): The full conversation text.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Contains \"emotion\" and \"emotion_score\" as keys.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following conversation between a doctor and a patient.\n",
        "\n",
        "    Extract only:\n",
        "    - Patient's primary emotional state (one word)\n",
        "    - Emotion score from 1 to 5 (1 = very distressed, 5 = calm)\n",
        "\n",
        "    Format your response exactly like this:\n",
        "    emotion:\n",
        "    emotion_score:\n",
        "\n",
        "    Conversation:\n",
        "    {conversation}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    raw_output = response.content.strip()\n",
        "\n",
        "    # Simple parsing without using Pydantic\n",
        "    result = {}\n",
        "    for line in raw_output.splitlines():\n",
        "        if \":\" in line:\n",
        "            key, value = line.split(\":\", 1)\n",
        "            result[key.strip()] = value.strip()\n",
        "\n",
        "    # Optional: Convert score to int\n",
        "    try:\n",
        "        result[\"emotion_score\"] = int(result[\"emotion_score\"])\n",
        "    except:\n",
        "        result[\"emotion_score\"] = None  # fallback if score parsing fails\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "e8OyJBxSAO5z"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def summarize_chief_complaint(conversation: str) -> dict:\n",
        "    \"\"\"\n",
        "    Summarizes the chief complaint and urgency of the patient from a doctor-patient conversation.\n",
        "\n",
        "    Parameters:\n",
        "    - conversation (str): The full doctor-patient conversation.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Contains 'chief_complaint' and 'urgency_level' (on a scale of 1–5).\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following doctor-patient conversation.\n",
        "\n",
        "    Extract:\n",
        "    1. Chief complaint (main health issue described by the patient) – a brief sentence.\n",
        "    2. Urgency level (1 to 5), where:\n",
        "       - 1 = not urgent\n",
        "       - 5 = extremely urgent and needs immediate attention\n",
        "\n",
        "    Format your response exactly like this:\n",
        "    chief_complaint:\n",
        "    urgency_level: <1-5>\n",
        "\n",
        "    Conversation:\n",
        "    {conversation}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    raw_output = response.content.strip()\n",
        "\n",
        "    # Parse response into dictionary\n",
        "    result = {}\n",
        "    for line in raw_output.splitlines():\n",
        "        if \":\" in line:\n",
        "            key, value = line.split(\":\", 1)\n",
        "            result[key.strip()] = value.strip()\n",
        "\n",
        "    try:\n",
        "        result[\"urgency_level\"] = int(result[\"urgency_level\"])\n",
        "    except:\n",
        "        result[\"urgency_level\"] = None\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "wyV4d67KAQBE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "emotion_tool = Tool(\n",
        "    name=\"EmotionDetectionTool\",\n",
        "    func=detect_patient_emotion,\n",
        "    description=\"Detect the patient's emotional state and return an emotion label and score from 1 to 5.\"\n",
        ")\n",
        "\n",
        "complaint_tool = Tool(\n",
        "    name=\"ChiefComplaintSummaryTool\",\n",
        "    func=summarize_chief_complaint,\n",
        "    description=\"Summarize the patient's chief complaint and determine urgency (low, medium, high).\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "jXGmjIaIAdNd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate # New import for the prompt template\n",
        "\n",
        "# Define your tools (assume emotion_tool and complaint_tool are already defined)\n",
        "tools = [emotion_tool, complaint_tool]\n",
        "\n",
        "# Define the prompt template for the tool calling agent\n",
        "# This replaces the need to import TOOL_CALLING_PROMPT directly\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "\n",
        "# Create the agent\n",
        "# Remove the 'output_parser' and 'format_scratchpad' arguments\n",
        "agent = create_tool_calling_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    prompt\n",
        ")\n",
        "\n",
        "\n",
        "# Wrap the agent into an executor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "untgehs6Ahuy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = \"\"\"\n",
        "Doctor: What brings you in today?\n",
        "Patient: I've been struggling with frequent headaches and blurred vision\n",
        "Doctor:I'll run a few tests to find the cause.\n",
        "\"\"\"\n",
        "\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": f\"Analyze this conversation:\\n{conversation}\\n\\nPlease detect the patient's emotional state and summarize the chief complaint with urgency.\"\n",
        "})\n",
        "\n",
        "print(response[\"output\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcCyQN46AmIn",
        "outputId": "7c37afcd-59b1-497a-c3a5-5e2a1c5b53d6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `EmotionDetectionTool` with `I've been struggling with frequent headaches and blurred vision`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'anxious': '', 'emotion_score': 2}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ChiefComplaintSummaryTool` with `I've been struggling with frequent headaches and blurred vision`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m{'chief_complaint': 'The patient has been experiencing frequent headaches and blurred vision.', 'urgency_level': 2}\u001b[0m\u001b[32;1m\u001b[1;3mThe patient's emotional state is anxious with a score of 2 out of 5. The chief complaint is frequent headaches and blurred vision, with a medium urgency level.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The patient's emotional state is anxious with a score of 2 out of 5. The chief complaint is frequent headaches and blurred vision, with a medium urgency level.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = \"\"\"\n",
        "Doctor: Hello! How are you feeling now?\n",
        "\n",
        "Patient: Hi doctor. I’m feeling much better. The headaches have reduced a lot.\n",
        "\n",
        "Doctor: That’s good to hear. What about the blurred vision?\n",
        "\n",
        "Patient: It’s almost gone. I only get it sometimes, but not like before.\n",
        "\n",
        "Doctor: Great. Have you been taking your medicine and following the advice?\n",
        "\n",
        "Patient: Yes, I took the medicine every day and also reduced my screen time.\n",
        "\n",
        "Doctor: Excellent. Any side effects from the medicine?\n",
        "\n",
        "Patient: Just felt a little sleepy in the beginning, but now it’s fine.\n",
        "\n",
        "Doctor: That’s normal. You can continue for a few more days, and then we’ll slowly stop it.\n",
        "\n",
        "Patient: Okay, doctor. Do I need any tests now?\n",
        "\n",
        "Doctor: Just a simple eye test to be sure. Nothing to worry about.\n",
        "\n",
        "Patient: Alright. Thank you so much!\n",
        "\n",
        "Doctor: You’re welcome. Keep taking care, and we’ll meet again in two weeks.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": f\"Analyze this conversation:\\n{conversation}\\n\\nPlease detect the patient's emotional state and summarize the chief complaint with urgency.\"\n",
        "})\n",
        "\n",
        "print(response[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xZwvP3xBh9e",
        "outputId": "30863c97-5da4-4e82-ab52-4b87b67b2696"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `EmotionDetectionTool` with `The patient is feeling much better, the headaches have reduced a lot.`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'relieved': '', 'emotion_score': None}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ChiefComplaintSummaryTool` with `blurred vision`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m{'chief_complaint': 'Blurred vision.', 'urgency_level': 3}\u001b[0m\u001b[32;1m\u001b[1;3mThe patient's emotional state is detected as 'relieved' with an emotion score of 5. The chief complaint is 'Blurred vision' with a high urgency level.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The patient's emotional state is detected as 'relieved' with an emotion score of 5. The chief complaint is 'Blurred vision' with a high urgency level.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**:Customer Review Extraction"
      ],
      "metadata": {
        "id": "4IAQWVL1CluW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the customer(name & ID), product and company details Extract the sentiment of the customer What was good or bad about the product- give specific details"
      ],
      "metadata": {
        "id": "HjnkDWYEDb7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field, ValidationError"
      ],
      "metadata": {
        "id": "BAGg5N_wCyS1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomerInfo(BaseModel):\n",
        "    name: str\n",
        "    id: str\n",
        "\n",
        "class ProductInfo(BaseModel):\n",
        "    name: str\n",
        "    id: str\n",
        "\n",
        "class ReviewAnalysis(BaseModel):\n",
        "    customer: CustomerInfo\n",
        "    product: ProductInfo\n",
        "    company: str\n",
        "    sentiment: str  # e.g., positive, neutral, negative\n",
        "    good_points: List[str]\n",
        "    bad_points: List[str]"
      ],
      "metadata": {
        "id": "YY2Z-QS9Dt_1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_review_insights(review: str) -> ReviewAnalysis:\n",
        "    prompt = f\"\"\"\n",
        "You are a review analysis expert.\n",
        "\n",
        "Extract the following details from the given customer review, and return ONLY a valid JSON object with no explanation or comments.\n",
        "\n",
        "Details to extract:\n",
        "- Customer name and ID\n",
        "- Product name and ID\n",
        "- Company/store name\n",
        "- Overall sentiment (positive, neutral, or negative)\n",
        "- Good points as a list\n",
        "- Bad points as a list (if none, return an empty list)\n",
        "\n",
        "Customer review:\n",
        "\\\"\\\"\\\"{review}\\\"\\\"\\\"\n",
        "\n",
        "Only return a valid JSON like this (no commentary!):\n",
        "{{\n",
        "  \"customer\": {{\n",
        "    \"name\": \"...\",\n",
        "    \"id\": \"...\"\n",
        "  }},\n",
        "  \"product\": {{\n",
        "    \"name\": \"...\",\n",
        "    \"id\": \"...\"\n",
        "  }},\n",
        "  \"company\": \"...\",\n",
        "  \"sentiment\": \"...\",\n",
        "  \"good_points\": [\"...\"],\n",
        "  \"bad_points\": [\"...\"]\n",
        "}}\n",
        "\"\"\"\n",
        "    # === Send prompt to LLM ===\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    raw_output = response.content.strip()\n",
        "\n",
        "    # === Attempt to extract JSON safely ===\n",
        "    try:\n",
        "        # Optional: extract only the first JSON block from the response\n",
        "        json_text = re.search(r\"\\{.*\\}\", raw_output, re.DOTALL).group()\n",
        "        parsed = json.loads(json_text)\n",
        "        return ReviewAnalysis(**parsed)\n",
        "    except (json.JSONDecodeError, ValidationError, AttributeError) as e:\n",
        "        print(\"⚠️ Failed to parse valid JSON. LLM response:\\n\", raw_output)\n",
        "        raise e"
      ],
      "metadata": {
        "id": "owCjHXiFDxj-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"\"\"\n",
        "@Customer: Varun D. Kapoor (ID#: CRM5543219) | Purchase Date: 22/10/2023 | Store: Croma Electronics, DLF Mall Branch, Sector 18, Noida, UP - 201301 | Product: Pebble BassX Prime™ Wireless Speaker (#PBL-SPK22) | Order #: CRM/DLF/2023/10/7788 ✨ What a FANTASTIC buy @ just ₹2,499/-! ... (full review)\n",
        "\"\"\"\n",
        "\n",
        "result = extract_review_insights(review_text)\n",
        "print(result.model_dump_json(indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNMv4217Edqi",
        "outputId": "0ef609dc-5be8-4e22-cb87-900389a83eeb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"customer\": {\n",
            "    \"name\": \"Varun D. Kapoor\",\n",
            "    \"id\": \"CRM5543219\"\n",
            "  },\n",
            "  \"product\": {\n",
            "    \"name\": \"Pebble BassX Prime Wireless Speaker\",\n",
            "    \"id\": \"PBL-SPK22\"\n",
            "  },\n",
            "  \"company\": \"Croma Electronics\",\n",
            "  \"sentiment\": \"positive\",\n",
            "  \"good_points\": [\n",
            "    \"What a FANTASTIC buy @ just ₹2,499/-!\"\n",
            "  ],\n",
            "  \"bad_points\": []\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}